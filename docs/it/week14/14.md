---
lang-ref: ch.14
lang: it
title: Settimana 14
translator: Marco Zullich
translation-date: 13 Oct 2020
---


## Lezione parte A

In questa sezione discutiamo delle previsioni strutturate. Innanzitutto introduciamo il grafo dei fattori basati sull'energia e di come svolgervi un'inferenza efficiente. Dopodiché diamo degli esempi di semplici grafi dei fattori basati sull'energia con fattori "superficiali". Infine, discutiamo della *Graph Transformer Net* ("rete di tipo *transformer* per grafi").


## Lezione parte B

La seconda parte della lezione approfondisce ulteriori applicazioni di metodi di modellazione grafica ai modelli basati sull'energia. Dopo aver passato del tempo a comparare diverse funzioni di perdita, discutiamo dell'applicazione dell'algoritmo di Viterbi e algoritmi "in avanti" alle reti *transformer* grafiche. Dopodiché passiamo a discutere della formulazione lagrangiana della retropropagazione e quindi dell'inferenza variazionale per modelli basati sull'energia.


## Pratica

Quando si devono addestrare modelli con un gran numero di parametri, come le reti neurali profonde, c'è un certo rischio di ottenere un sovradattamento (*overfitting*) nei confronti dei dati di addestramento. A ciò segue un maggiore errore di generalizzazione. Al fine di ridurre il sovradattamento, possiamo introdurre della regolarizzazione nel nostro addestramento, scoraggiando certe soluzioni, riducendo la misura entro cui i nostri modelli si adattano al rumore.